{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fd5b2b",
   "metadata": {},
   "source": [
    "# Basic Pipeline\n",
    "\n",
    "1. Extract the PDF into text (using PyMuPDF for structure).\n",
    "2. Chunk and embed text with OpenAIâ€™s ADA.\n",
    "3. Store embeddings in ChromaDB.\n",
    "4. Ingest each Rule (and its references) into Neo4j via Cypher.\n",
    "5. Build a hybrid RAG retriever that combines vector and graph queries.\n",
    "6. Wire up a LangChain chain using GPT-4o to generate precise, rule-based answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1607b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In your notebook or terminal\n",
    "!pip install pymupdf langchain chromadb neo4j openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d777e12",
   "metadata": {},
   "source": [
    "#  Load and parse the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f34f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_pages(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages = []\n",
    "    for page in doc:\n",
    "        text = page.get_text(\"text\")\n",
    "        pages.append(text)\n",
    "    return pages\n",
    "\n",
    "pages = extract_pages(\"Rules of Golf for 2019 (Final).pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def34e5e",
   "metadata": {},
   "source": [
    "# Chunk and embed with ADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "# Set your OpenAI key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR_OPENAI_KEY>\"\n",
    "\n",
    "# Split into ~500-token chunks with overlap\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500, chunk_overlap=200\n",
    ")\n",
    "docs = []\n",
    "for i, page in enumerate(pages):\n",
    "    for chunk in splitter.split_text(page):\n",
    "        docs.append({\"page\": i+1, \"text\": chunk})\n",
    "\n",
    "# Create embeddings\n",
    "embedder = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "texts = [d[\"text\"] for d in docs]\n",
    "metadatas = [{\"page\": d[\"page\"]} for d in docs]\n",
    "embeddings = embedder.embed_documents(texts)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
